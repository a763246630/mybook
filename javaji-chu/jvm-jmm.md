\[TOC\]

### JMM

JMM（Java Memory Model）即java内存模型

了解jvm内存模型前，了解下cpu和计算机内存的交互情况。【因为Java虚拟机内存模型定义的访问操作与计算机十分相似】

#### CPU和内存的交互

在计算机中，cpu和内存的交互最为频繁，相比内存，磁盘读写太慢，内存相当于高速的缓冲区。

但是随着cpu的发展，内存的读写速度也远远赶不上cpu。因此cpu厂商在每颗cpu上加上高速缓存，用于缓解这种情况。现在cpu和内存的交互大致如下。

![](/assets/jvm1.png)

cpu上加入了高速缓存这样做解决了处理器和内存的矛盾\(一快一慢\)，但是引来的新的问题 - **缓存一致性**

在多核cpu中，每个处理器都有各自的高速缓存，而主内存确只有一个 。

```
CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找，每个cpu有且只有一套自己的缓存。
```

如何保证多个处理器运算涉及到同一个内存区域时，多线程场景下会存在缓存一致性问题，那么运行时保证数据一致性？

为了解决这个问题，各个处理器需遵循一些协议保证一致性。【如MSI，MESI协议。。】java采用volatile实现变量共享

![](/assets/jvm3.png)

#### 缓存一致性协议

**多线程环境下存在的问题**

**缓存一致性问题**

在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存

（MainMemory）。基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是

也引入了新的问题：缓存一致性（CacheCoherence）。当多个处理器的运算任务都涉及同一

块主内存区域时，将可能导致各自的缓存数据不一致的情况，如果真的发生这种情况，那同步

回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都

遵循一些协议，在读写时要根据协议来进行操作，这类协议有**MSI**、

**MESI**（IllinoisProtocol）、MOSI、Synapse、Firefly及DragonProtocol，等等

MESI

由于每个处理器都含有私有的高速缓存，在对缓存中数据进行更新后，其他处理器中所含有的该共享变量的缓存如果被处理器进行读操作，就会出现错误。有些计算机采用LOCK\#信号对总线进行锁定，当一个处理器在总线上输出此信号时，其它处理器的请求将被阻塞，那么该处理器就能独自共享内存。然而总线锁定的开销太大，在之后的计算机中一般都采用“缓存锁定”的方式实现。  
MESI是代表了缓存数据的四种状态的首字母，分别是Modified、Exclusive、Shared、Invalid）

* M\(Modified\)：被修改的。处于这一状态的数据，只在本CPU中有缓存数据，而其他CPU中没有。同时其状态相对于内存中的值来说，是已经被修改的，且没有更新到内存中。 
* E\(Exclusive\)：独占的。处于这一状态的数据，只有在本CPU中有缓存，且其数据没有修改，即与内存中一致。 
* S\(Shared\)：共享的。处于这一状态的数据在多个CPU中都有缓存，且与内存一致。 
* I\(Invalid\)：要么已经不在缓存中，要么它的内容已经过时。为了达到缓存的目的，这种状态的段将会被忽略。一旦缓存段被标记为失效，那效果就等同于它从来没被加载到缓存中。 
  在缓存行中有这四种状态的基础上，通过“嗅探”技术完成以下功能：【嗅探技术能够嗅探其他处理器访问主内存和它们的内部缓存】 
* 一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回CPU。 
* 一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。 
* 一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。
* 只有E和M可以进行写操作而且不需要额外操作，如果想对S状态的缓存字段进行写操作，那必须先发送一个RFO\(Request-For-Ownership\)广播，该广播可以让其他CPU的缓存中的相同数据的字段实效，即变成I状态。 
  通过以上机制可以使得处理器在每次读写操作都是原子的，并且每次读到的数据都是最新的

![](/assets/jvm11.png)

#### 主内存

共享内存

#### 工作内存（高速缓存）

线程隔离

#### JMM-同步八种操作介绍

（1）**lock\(锁定\)**：作用于主内存的变量，把一个变量标记为一条线程独占状态

（2）**unlock\(解锁\)**：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的

变量才可以被其他线程锁定

（3）**read\(读取\)**：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，

以便随后的load动作使用

（4）**load\(载入\)**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作

内存的变量副本中

（5）**use\(使用\)**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎

（6）**assign\(赋值\)**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存

的变量

（7）**store\(存储\)**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，

以便随后的write的操作

（8）**write\(写入\)**：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送

到主内存的变量中

如果要把一个变量从主内存中复制到工作内存中，就需要按顺序地执行read和load操作，

如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。但Java内

存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。

### JVM

#### JIT（即时编译） 技术。

在Java的编译体系中，一个Java的源代码文件变成计算机可执行的机器指令的过程中，需要经过两段编译，第一段是把.java文件转换成.class文件。第二段编译是把.class转换成机器指令的过程。

第一段编译就是javac命令。

在第二编译阶段，JVM 通过解释字节码将其翻译成对应的机器指令，逐条读入，逐条解释翻译。很显然，经过解释执行，其执行速度必然会比可执行的二进制字节码程序慢很多。这就是传统的JVM的解释器（Interpreter）的功能。为了解决这种效率问题，引入了 JIT（即时编译） 技术。

引入了 JIT 技术后，Java程序还是通过解释器进行解释执行，当JVM发现某个方法或代码块运行特别频繁的时候，就会认为这是“热点代码”（Hot Spot Code\)。然后JIT会把部分“热点代码”翻译成本地机器相关的机器码，并进行优化，然后再把翻译后的机器码缓存起来，以备下次使用。

#### 逃逸分析

逃逸分析的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。

```
public static StringBuffer craeteStringBuffer(String s1, String s2) {
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    return sb;
}

public static String createStringBuffer(String s1, String s2) {
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
   return sb.toString();

}
```

第一段代码中的sb对象就逃逸了，而第二段代码中的sb对象就没有逃逸。

使用逃逸分析，编译器可以对代码做如下优化：

一、同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。

二、将堆分配转化为栈分配。如果一个对象不会发生逃逸，该对象可能是栈分配的候选，而不是堆分配。

三、分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。

在Java代码运行时，通过JVM参数可指定是否开启逃逸分析，

-XX:+DoEscapeAnalysis ： 表示开启逃逸分析

-XX:-DoEscapeAnalysis ： 表示关闭逃逸分析 从jdk 1.7开始已经默认开始逃逸分析，如需关闭，需要指定-XX:-DoEscapeAnalysis

#### 锁消除（同步块省略）

在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。

如果同步块所使用的锁对象通过这种分析被证实只能够被一个线程访问，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步。这个取消同步的过程就叫同步省略，也叫锁消除。

```
public void test() { 
//这里锁不会生效 
    synchronized(new Object()) { 

    }

}
```

#### 锁粗化

通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源，因为锁的请求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。连续的多次加锁这种情况可以把锁粒度加大，以降低短时间内大量锁请求、同步、释放带来的性能损耗、。

```
极端情况
public void test(){
    synchronizd(obj){
        //dosomething
    }
    //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕
    synchronized(obj){
       //dosomething
    }
  }
优化成
public void test(){
    synchronized(obj){
       //dosomething

    //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕

       //dosomething
    }
  }
```

#### 标量替换

标量（Scalar）是指一个无法再分解成更小的数据的数据。Java中的原始数据类型就是标量。相对的，那些还可以分解的数据叫做聚合量（Aggregate），Java中的对象就是聚合量，因为他可以分解成其他聚合量和标量。

在JIT阶段，如果经过逃逸分析，**发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替。这个过程就是标量替换**。那么标量替换有什么好处呢？就是可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。

#### 栈上分配（对象并不一定都是在堆上分配内存的。）

在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。其实在现有的虚拟机中，并没有真正的实现栈上分配，其实是标量替换实现的。

#### JVM结构

![](/assets/jvm结构.png)

#### 堆

先进先出

存储对象的实例

#### 虚拟机栈

先进后出

栈中存放一些基本类型的变量数据（int/short/long/byte/float/double/Boolean/char）和对象引用（指向堆内存）。

数组引用变量是存放在栈内存中，数组元素是存放在堆内存中。

#### 本地方法栈

#### 程序计数器

#### 方法区



#### 常量池



