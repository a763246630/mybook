## 常见的并发问题和解决并发方案

[TOC]



#### 常见的并发问题

1.多个线程同时去修改一个共享变量时造成数据错乱;

2.先查询判断数据不存在再添加，多个线程同时去查询的时候都是不存在所以造成插入重复数据;

3.并发请求同一个业务造成业务重复执行如用户账户余额增加或减少多次执行；

#### 常见的锁

服务级锁（JVM级）

**显式锁**:需要手动加解锁 ,juc包，灵活度更好 Lock ReentrantLock

**隐式锁**:jvm 内置锁,不需要手动加解锁   Syncronized

**锁提供了两种主要特性：原子性和可见性。**

#### 原子性

一次只允许一个线程持有某个特定的锁，只有持有锁的线程能够使用加锁的共享数据。可以通过 synchronized和 

Lock实现原子性。因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。

#### 可见性

当一个共享变量被volatile修饰时，它会保证修改的值立即被 

其他的线程看到，即修改的值立即更新到主存中，当其他线程需要读取时，它会去内存中读取 

新值。synchronized和Lock也可以保证可见性，因为它们可以保证任一时刻只有一个线程能 

访问共享资源，并在其释放锁之前将修改的变量刷新到内存中。 

#### 有序性

在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述 

volatile关键字）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized 

和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就 

保证了有序性。

### Volatile

**Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。**



#### 指令重排序

java语言规范规定JVM线程内部维持顺序化语义。即只要程序的**最终结果不变**（特殊情况CPU感知不到会影响程序

结果也会导致最终结果不同,使用共享变量要注意防止指令重排影响程序的正常运行），那么指令的**执行顺序可以**

**与代码顺序不一致**，此过程叫指令的重排序。

指令重排序的意义是什么？JVM能根据处理器特性（CPU多级缓存系统、多核处理器等） 

适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性 

能。

锁和volatile 关键词修饰的共享变量 用内存屏障解决指令重排的问题。

**volatile 的读性能消耗与普通变量几乎相同，但是写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。**

#### 内存屏障

禁止屏障之前指令与屏障之后的指令。

内存屏障分为两种：**Load Barrier 和 Store Barrier即读屏障和写屏障。**
内存屏障有两个作用：

> **1.阻止屏障两侧的指令重排序；2.强制把写缓冲区/高速缓存（工作内存）中的脏数据等写回主内存，让缓存中相应的数据失效。**

- 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；
- 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。

**java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。**

> **LoadLoad屏障：**对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
> **StoreStore屏障：**对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
> **LoadStore屏障：**对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
> **StoreLoad屏障：**对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

Java虚拟机底层实际上是借助内存屏障（ Memory Barrier ，也称 Fence ）来实现上述两个动作的。内存屏障是对一类仅针对内存读、写操作指令 （ Instruction ） 的跨处理器架构 （ 比如 x86 、ARM ）的比较底层的抽象（ 或者称呼 ）。内存屏障是被插入到两个指令之间进行使用的，其作用是禁止编译器、处理器重排序从而保障有序性。它在指令序列 （ 如指令 1 ；指令2 ；指令3 ）中就像是一堵墙 （ 因此被称为屏障 ）一样使其两侧 （ 之前和之后 ）的指令无法“穿越”它 （ 一旦穿越了就是重排序了 ）。但是，为了实现禁止重排序的功能，这些指令也往往具有一个副作用刷新处理器缓存、冲刷处理器缓存，从而保证可见性。

不同微架构的处理器所提供的这样的指令是不同的，并且出于不同的目的使用的相应指令也是不同的。例如对于 “写-写” （ 写后写 ） 操作，如果仅仅是为了防止 （ 禁止 ） 重排序而对可见性保障没有要求，那么在x86架构的处理器下使用空操作就可以了（  因为 x86处理器不会对 “写-写” 操作进行重排序 ）。而如果对可见性有要求（比如前一个写操作的结果要在后一个写操作执行前对其他处理器可见），那么在x86    处理器下需要使用LOCK 前缀指令或者sfence 指令、mfence 指令；在 ARM 处理器下则需要使用 DMB 指令。

Java虚拟机会在 MonitorExit （ 释放锁 ） 对应的机器码指令之后插入一个存储屏障，这就保障了写线程在释放锁之前在临界区中对共享变量所做的更新对读线程的执行处理器来说是可同步的。相应地，Java 虚拟机会在 MonitorEnter （ 申请锁 ） 对应的机器码指令之后临界区开始之前的地方插入一个加载屏障，这使得读线程的执行处理器能够将写线程对相应共享变量所做的更新从其他处理器同步到该处理器的高速缓存中。因此，可见性的保障是通过写线程和读线程成对地使用存储屏障和加载屏障实现的。

#### 总线风暴

由于volatile的mesi缓存一致性协议需要不断的从主内存嗅探和cas不断循环无效交互导致总线带宽达到峰值
解决办法：部分volatile和cas使用synchronize

#### 按照有序性保障来划分

内存屏障可以分为获取屏障（Acquire Barrier）和释放屏障 （ Release Barrier ）。

获取屏障的 使 用 方 式 是 在 一 个 读 操 作 （ 包括 Read-Modify-Write 以及普通的读操作 ）之后插入该内存屏障，其作用是禁止该读操作与其后的任何读写操作之间进行重排序，这相当于在进行后续操作之前先要获得相应共享数据的所有权 （ 这也是该屏障的名称来源 ）。释放屏障的使用方式是在一个写操作之前插入该内存屏障，其作用是禁止该写操作与其前面的任何读写操作之间进行重排序。这相当于在对相应共享数据操作结束后释放所有权（ 这也是该屏障的名称来源 ）。 **Java虚拟机会在 MonitorEnter（ 它包含了读操作 ） 对应的机器码指令之后临界区开始之前的地方插入一个获取屏障，并在临界区结束之后 MonitorExit （ 它包含了写操作 ） 对应的机器码指令之前的地方插入一个释放屏障。**因此，这两种屏障就像是三明治的两层面包片把火腿夹住一样把临界区中的代码（指令序列）包括起来

### ReentrantLock

数据库锁

乐观锁

利用版本号或数据修改之前查询的状态作为更新条件（原理查询修改之前的数据版本号，跟修改时的数据版本号对比相同则更新，如果相同则代表数据没有被其他线程修改过。）

悲观锁

业务开始时先用for update 锁住要修改的行，修改完再释放for update

应用级锁（全局锁）

redis锁

setnx

zookeeper锁

创建一个持久化有序节点

在节点下再每个线程创建临时有序节点，判断当前节点是不是最小节点，是最小节点则获取到锁

### AQS 抽象队列同步器

AbstractQueueSyncronizer 由两种 等待队列 和条件队列组成

Sync同步器

state 记录上锁次数

exclusiveOwnerThread 独占锁的线程

锁 特性管理

阻塞等待队列 

共享/独占

公平/非公平

##### 可重入

多次获取锁，递归里面调用一个带锁的方法（不可重入会造成死锁）

允许中断



### Syncronized JVM内置锁 原理

**显式锁**:需要手动加解锁 ,juc包，灵活度更好

不能跨方法.

```
synchronized(对象){



}//括号开始结束是锁的范围
```

Lock

synchronized内置锁是一种对象锁\(锁的是对象而非引用\)，作用粒度是对象，可以用来实现对临界资源的同步互斥访问，是可重入的。

加锁的方式：

同步实例方法，锁是当前实例对象

同步类方法，锁是当前类对象

同步代码块，锁是括号里面的对象

synchronized是基于JVM内置锁实现，通过内部对象Monitor\(监视器锁\)实现，基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖 底层操作系统的Mutex lock（互斥锁）实现，它是一个重量级锁性能较低（在java1.5及以前）。JVM内置锁在1.5之后版本做了重大的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等 技术来减少锁操作的开销，，内置锁的并发性能已经基本与Lock持平。

synchronized关键字被编译成字节码后会被翻译成monitorenter 和 monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置。

![](/assets/sync1.png)

每个同步对象都有一个自己的Monitor\(监视器锁\)，加锁过程如下图所示：

##### ![](/assets/sync2.png)

锁状态是被记录在每个对象的对象头（Mark Word）

##### 对象的内存布局

HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：

对象头（Header）：比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象）等

实例数据（Instance Data）：即创建对象时，对象中成员变量，方法等

对齐填充（Padding）：对象的大小必须是8字节的整数倍

![](/assets/sync3.png)

对象头

HotSpot虚拟机的对象头包括两部分信息，第一部分是“Mark Word”，用于存储对象自身的运行时数据， 如**哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳**等等，这部分数据的长度在32位和64位的虚拟机（暂 不考虑开启压缩指针的场景）中分别为32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额 外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下。

![](/assets/sync4.png)

但是如果对象是数组类型，则需要三个机器码，因为JVM虚拟机可以通过

Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数

组的大小，所以用一块来记录数组长度。

对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟

机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内

存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，

Mark Word会随着程序的运行发生变化，变化状态如下（32位虚拟机）：

![](/assets/sync5.png)

##### 

#### 锁的膨胀升级过程 

Syncronized锁的膨胀 无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁

锁的状态总共有四种，**无锁状态、偏向锁、轻量级锁和重量级锁**。随着锁的 竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级。

##### 无锁

不通过阻塞的方式来访问并修改资源。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改线程会修改失败，前文提到的CAS就是一个无锁的形式。

**偏向锁** 

偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引 入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从 而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失效后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。

假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。
在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行**加锁**或者**解锁**操作， 

当线程 1 访问同步块（为无锁状态）时通过CAS成功获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，因为偏向锁不会主动释放锁，因此以后线程 1 再次获取锁的时候，需要比较当前线程的线程 ID 和对象头中的线程 ID 是否一致.

如果一致（还是线程 1 获取锁对象），则无需使用 CAS 来加锁、解锁；

如果不一致（其他线程，如线程 2 要竞争锁对象，而偏向锁不会主动释放因此还是存储的线程 1 的线程 ID），那么需要查看对象头中记录的线程 1 是否存活，如果没有存活，那么锁对象被重置为无锁状态，其它线程（线程 2）可以竞争将其设置为偏向锁；

如果存活，那么立刻查找该线程（线程 1）的栈帧信息，如果还是需要继续持有这个锁对象，那么挂机当前线程 1，撤销偏向锁，升级为轻量级锁，如果线程 1 不再使用该锁对象，那么将锁对象状态设为无锁状态，重新偏向新的线程。

**轻量级锁** 

轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 

**锁消除** 

消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编 译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种 方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的 append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量， 并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情 景，JVM会自动将其锁消除。

**自旋**

当有个线程A去请求某个锁的时候，这个锁正在被其它线程占用，但是线程A并不会马上进入阻塞状态，而是**循环请求锁(自旋)**。这样做的目的是因为很多时候持有锁的线程会很快释放锁的，线程A可以尝试一直请求锁，没必要被挂起放弃CPU时间片，因为线程被挂起然后到唤醒这个过程开销很大,当然如果线程A自旋指定的时间还没有获得锁，仍然会被挂起。

**自适应性自旋**

自适应性自旋是自旋的升级、优化，**自旋的时间不再固定**，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态决定。例如线程如果自旋成功了，那么下次自旋的次数会增多，因为JVM认为既然上次成功了，那么这次自旋也很有可能成功，那么它会允许自旋的次数更多。反之，如果对于某个锁，**自旋很少成功，那么在以后获取这个锁的时候，自旋的次数会变少甚至忽略，避免浪费处理器资源**。有了自适应性自旋，随着程序运行和性能监控信息的不断完善，JVM对程序锁的状况预测就会变得越来越准确，JVM也就变得越来越聪明。

#### 锁粗化

在使用锁的时候，需要让同步块的作用范围尽可能小，这样做的目的是**为了使需要同步的操作数量尽可能小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁**。

**逃逸分析** 

使用逃逸分析，编译器可以对代码做如下优化： 

一、同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可 

以不考虑同步。 

二、将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远 

不会逃逸，对象可能是栈分配的候选，而不是堆分配。 

三、分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问 

到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。 

**获取锁过程**

1.在线程进入同步方法、同步块的时候，如果同步对象锁状态为无锁状态(锁标志位为"01"状态，是否为偏向锁为"0")，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Recored)的空间，用于储存锁对象目前的Mark Word的拷贝(官方把这份拷贝加了个Displaced前缀，即Displaced Mark Word)。

2.将对象头的Mark Word拷贝到线程的锁记录(Lock Recored)中。

3.拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新成功了，则执行步骤4，否则执行步骤5。

4.更新成功，这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为"00"，即表示此对象处于轻量级锁的状态。。

5.更新失败，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行，否则说明这个锁对象已经被其其它线程抢占了。进行自旋执行步骤3，如果自旋结束仍然没有获得锁，轻量级锁就需要膨胀为重量级锁，锁标志位状态值变为"10"，Mark Word中储存就是指向monitor对象的指针，当前线程以及后面等待锁的线程也要进入阻塞状态。

**释放锁的过程**

使用CAS操作将对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来(依据Mark Word中锁记录指针是否还指向本线程的锁记录)，如果替换成功，则执行步骤2，否则执行步骤3。
如果替换成功，整个同步过程就完成了，恢复到无锁的状态(01)。

如果替换失败，说明有其他线程尝试获取该锁(此时锁已膨胀)，那就要在释放锁的同时，唤醒被挂起的线程。

 

 

