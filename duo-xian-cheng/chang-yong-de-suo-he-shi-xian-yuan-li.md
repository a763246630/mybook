## 常见的并发问题和解决并发方案

\[TOC\]

#### 常见的并发问题

1.多个线程同时去修改一个共享变量时造成数据错乱;

2.先查询判断数据不存在再添加，多个线程同时去查询的时候都是不存在所以造成插入重复数据;

3.并发请求同一个业务造成业务重复执行如用户账户余额增加或减少多次执行；

#### 常见的锁

服务级锁（JVM级）

**显式锁**:需要手动加解锁 ,juc包，灵活度更好 Lock ReentrantLock

**隐式锁**:jvm 内置锁,不需要手动加解锁   Syncronized

**锁提供了两种主要特性：原子性和可见性。**

#### 原子性

一次只允许一个线程持有某个特定的锁，只有持有锁的线程能够使用加锁的共享数据。可以通过 synchronized和

Lock实现原子性。因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。

#### 可见性

当一个共享变量被volatile修饰时，它会保证修改的值立即被

其他的线程看到，即修改的值立即更新到主存中，当其他线程需要读取时，它会去内存中读取

新值。synchronized和Lock也可以保证可见性，因为它们可以保证任一时刻只有一个线程能

访问共享资源，并在其释放锁之前将修改的变量刷新到内存中。

#### 有序性

在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述

volatile关键字）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized

和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就

保证了有序性。

### Volatile

**Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。**

#### 指令重排序

java语言规范规定JVM线程内部维持顺序化语义。即只要程序的**最终结果不变**（特殊情况CPU感知不到会影响程序

结果也会导致最终结果不同,使用共享变量要注意防止指令重排影响程序的正常运行），那么指令的**执行顺序可以**

**与代码顺序不一致**，此过程叫指令的重排序。

指令重排序的意义是什么？JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）

适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性

能。

锁和volatile 关键词修饰的共享变量 用内存屏障解决指令重排的问题。

**volatile 的读性能消耗与普通变量几乎相同，但是写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。**

#### 内存屏障

禁止屏障之前指令与屏障之后的指令。

内存屏障分为两种：**Load Barrier 和 Store Barrier即读屏障和写屏障。**  
内存屏障有两个作用：

> **1.阻止屏障两侧的指令重排序；2.强制把写缓冲区/高速缓存（工作内存）中的脏数据等写回主内存，让缓存中相应的数据失效。**

* 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；
* 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。

**java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。**

> **LoadLoad屏障：**对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。  
> **StoreStore屏障：**对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。  
> **LoadStore屏障：**对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。  
> **StoreLoad屏障：**对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

Java虚拟机底层实际上是借助内存屏障（ Memory Barrier ，也称 Fence ）来实现上述两个动作的。内存屏障是对一类仅针对内存读、写操作指令 （ Instruction ） 的跨处理器架构 （ 比如 x86 、ARM ）的比较底层的抽象（ 或者称呼 ）。内存屏障是被插入到两个指令之间进行使用的，其作用是禁止编译器、处理器重排序从而保障有序性。它在指令序列 （ 如指令 1 ；指令2 ；指令3 ）中就像是一堵墙 （ 因此被称为屏障 ）一样使其两侧 （ 之前和之后 ）的指令无法“穿越”它 （ 一旦穿越了就是重排序了 ）。但是，为了实现禁止重排序的功能，这些指令也往往具有一个副作用刷新处理器缓存、冲刷处理器缓存，从而保证可见性。

不同微架构的处理器所提供的这样的指令是不同的，并且出于不同的目的使用的相应指令也是不同的。例如对于 “写-写” （ 写后写 ） 操作，如果仅仅是为了防止 （ 禁止 ） 重排序而对可见性保障没有要求，那么在x86架构的处理器下使用空操作就可以了（  因为 x86处理器不会对 “写-写” 操作进行重排序 ）。而如果对可见性有要求（比如前一个写操作的结果要在后一个写操作执行前对其他处理器可见），那么在x86    处理器下需要使用LOCK 前缀指令或者sfence 指令、mfence 指令；在 ARM 处理器下则需要使用 DMB 指令。

Java虚拟机会在 MonitorExit （ 释放锁 ） 对应的机器码指令之后插入一个存储屏障，这就保障了写线程在释放锁之前在临界区中对共享变量所做的更新对读线程的执行处理器来说是可同步的。相应地，Java 虚拟机会在 MonitorEnter （ 申请锁 ） 对应的机器码指令之后临界区开始之前的地方插入一个加载屏障，这使得读线程的执行处理器能够将写线程对相应共享变量所做的更新从其他处理器同步到该处理器的高速缓存中。因此，可见性的保障是通过写线程和读线程成对地使用存储屏障和加载屏障实现的。

#### 总线风暴

由于volatile的mesi缓存一致性协议需要不断的从主内存嗅探和cas不断循环无效交互导致总线带宽达到峰值  
解决办法：部分volatile和cas使用synchronize

#### 按照有序性保障来划分

内存屏障可以分为获取屏障（Acquire Barrier）和释放屏障 （ Release Barrier ）。

获取屏障的 使 用 方 式 是 在 一 个 读 操 作 （ 包括 Read-Modify-Write 以及普通的读操作 ）之后插入该内存屏障，其作用是禁止该读操作与其后的任何读写操作之间进行重排序，这相当于在进行后续操作之前先要获得相应共享数据的所有权 （ 这也是该屏障的名称来源 ）。释放屏障的使用方式是在一个写操作之前插入该内存屏障，其作用是禁止该写操作与其前面的任何读写操作之间进行重排序。这相当于在对相应共享数据操作结束后释放所有权（ 这也是该屏障的名称来源 ）。 **Java虚拟机会在 MonitorEnter（ 它包含了读操作 ） 对应的机器码指令之后临界区开始之前的地方插入一个获取屏障，并在临界区结束之后 MonitorExit （ 它包含了写操作 ） 对应的机器码指令之前的地方插入一个释放屏障。**因此，这两种屏障就像是三明治的两层面包片把火腿夹住一样把临界区中的代码（指令序列）包括起来

#### as-if-serial语义

as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线

程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。

为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因

为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被

编译器和处理器重排序。

#### happens-before 原则

只靠sychronized和volatile关键字来保证原子性、可见性以及有序性，那么编写并发程序

可能会显得十分麻烦，幸运的是，从JDK 5开始，Java使用新的JSR-133内存模型，提供了

happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数

据是否存在竞争、线程是否安全的依据，happens-before 原则内容如下

\1. 程序顺序原则，即在一个线程内必须保证语义串行性，也就是说按照代码顺序执行。

\2. 锁规则 解锁\(unlock\)操作必然发生在后续的同一个锁的加锁\(lock\)之前，也就是说，

如果对于一个锁解锁后，再加锁，那么加锁的动作必须在解锁动作之后\(同一个锁\)。

\3. volatile规则 volatile变量的写，先发生于读，这保证了volatile变量的可见性，简单

的理解就是，**volatile变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当**

**该变量发生变化时，又会强迫将最新的值刷新到主内存**，**任何时刻，不同的线程总是能**

**够看到该变量的最新值**。

\4. 线程启动规则 线程的start\(\)方法先于它的每一个动作，即如果线程A在执行线程B的

start方法之前修改了共享变量的值，那么当线程B执行start方法时，线程A对共享变量

的修改对线程B可见

\5. 传递性 A先于B ，B先于C 那么A必然先于C

\6. 线程终止规则 线程的所有操作先于线程的终结，Thread.join\(\)方法的作用是等待当前

执行的线程终止。假设在线程B终止之前，修改了共享变量，线程A从线程B的join方法

成功返回后，线程B对共享变量的修改将对线程A可见。

\7. 线程中断规则 对线程 interrupt\(\)方法的调用先行发生于被中断线程的代码检测到中

断事件的发生，可以通过Thread.interrupted\(\)方法检测线程是否中断。

\8. 对象终结规则 对象的构造函数执行，结束先于finalize\(\)方法

### ReentrantLock

数据库锁

乐观锁

利用版本号或数据修改之前查询的状态作为更新条件（原理查询修改之前的数据版本号，跟修改时的数据版本号对比相同则更新，如果相同则代表数据没有被其他线程修改过。）

悲观锁

业务开始时先用for update 锁住要修改的行，修改完再释放for update

应用级锁（全局锁）

redis锁

setnx

zookeeper锁

创建一个持久化有序节点

在节点下再每个线程创建临时有序节点，判断当前节点是不是最小节点，是最小节点则获取到锁

### AQS 抽象队列同步器

AQS具备特性

#### 共享/独占

共享锁与独占锁最大的区别在于，独占锁是**独占的，排他的**，因此在独占锁中有一个`exclusiveOwnerThread`属性，用来记录当前持有锁的线程。**当独占锁已经被某个线程持有时，其他线程只能等待它被释放后，才能去争锁，并且同一时刻只有一个线程能争锁成功。**

#### 公平锁获取锁过程

ReentrantLock lock=new ReentrantLock \(true\);//true 实例化FairSync为公平锁

两个子类FairSync，NonfairSync来实现ReentrantLock 里的成员变量Sync同步器

```
1.公平锁调用FairSync类的lock()>>acquire(1)>>tryAcquire
尝试获取锁
 如果锁的state为0（锁没有被占用），则判断
     如果当前节点没有有前驱节点，并且CAS替换state锁状态为1获取独占锁次数加1,设置setExclusiveOwnerThread为当前线程，有则获取锁失败(公平锁必须让排队让前驱节点先获取锁).
 如果state不为0，则判断getExclusiveOwnerThread()当前独占线程是否是当前线程，不是则获取锁失败，是当前线程将state加1(获取锁次数加1).
2.如果获取锁失败，则调用acquireQueued(addWaiter(Node.EXCLUSIVE), arg)>>addWaiter(Node mode)
新建一个nextWaiter为null的Node节点放入到同步队列中（CAS替换tail指向当前节点）如果失败循环执行。
  2.1执行>>acquireQueued
  2.1.1判断当前节点的前驱节点是否是head,
  如果是则调用tryAcquire尝试获取锁如果成功则将当前结点设置为头结点(head),当前节点的下一个节点等null，返回true获取锁成功
  如果前驱节点不是Head或者tryAcquire失败,
    则调用>>shouldParkAfterFailedAcquire
        判断当前节点的前驱节点的waitStatus 是否为-1（signal信号），是则返回true,不是则判断当前节点的前驱节点的waitStatus是否大于0(前驱节点状态如果被取消状态，将被移除出队列)，为0则将当前节点移出队列.小于0则将当前节点的前驱节点的waitStatus用CAS替换为-1（signal信号）返回false，
    然后调用>>parkAndCheckInterrupt方法阻塞当前节点，返回true（ LockSupport.park 底层实现逻辑调用系统内核功能 pthread_mutex_lock 阻塞线程）.
    如果parkAndCheckInterrupt阻塞失败，会从2.1.1开始轮询执行上面的操作。

    如果前面的循环出现异常则调用>>cancelAcquire去取消获取锁
       如果当前节点的前驱节点的waitStatus > 0,将当前节点的前驱节点移除队列。
    当前节点的前驱节点指向当前节点的前驱节点的前驱节点。然后将当前节点的waitStatus改成CANCELLED（1取消）.
       如果当前节点是tail尾结点并且CAS替换tail为当前节点的前驱节点成功，然后CAS替换当前节点的前驱节点的下一个节点为null.
       如果当前节点不是tail尾结点或者CAS替换tail为当前节点的前驱节点失败，
          判断如果当前节点的前驱节点不等于head并且(当前节点的前驱节点的waitStatus是否为（signal信号）或者前驱节点的waitStatus小于等于0（不为取消）CAS替换当前节点的前驱节点的waitStatus为（signal信号）)并且当前节点的前驱节点的线程不为空，则（判断如果节点的下一个节点的不为空并且waitStatus小于等于0，是则CAS替换前节点的前驱节点的下一个节点为当前节点的下一个节点）,
          否则（调用>>unparkSuccessor，如果当前节点的waitStatus小于0则CAS替换
为0，然后如果当前节点的下一个节点为空或者当前节点的下一个节点的waitStatus大于0,则循环从尾结点开始向前找出不等于当前节点一个waitStatus小于等于0的节点，节点不会空则唤醒这个节点，然后如果当前节点的下一个节点不为空或者当前节点的下一个节点的waitStatus小于等于0,则唤醒当前节点的下一个节点
)


如果shouldParkAfterFailedAcquire或者parkAndCheckInterrupt都返回true.则执行selfInterrupt()中断线程.
```

主要步骤

1. 尝试获取锁（如果当前节点没有前驱节点，CAS替换state+1，或者独占线程为当前线程则成功），获取失败就创建一个独占节点用CAS替换tail\(放入同步队列尾部\)，

2. 如果当前节点的前驱节点是head再次尝试获取锁，

​               如果成功，将当前节点设为head;

​                如果失败,阻塞当前线程。

公平锁释放锁过程

```
>>unlock>>sync.release>>tryRelease
判断当前线程是不是exclusiveOwnerThread(持有锁的独占线程)，不是直接抛出异常
如果是，获取state（锁次数）减1，如果state等于0锁的exclusiveOwnerThread(持有锁的独占线程)赋值为空,
返回成功。
如果tryRelease成功，判断head节点不为空并且head节点的waitStatus!=0，唤醒head节点unparkSuccessor(h),返回true

如果tryRelease失败直接返回false释放失败.
```

#### 非公平锁获取锁过程

```
1.直接compareAndSetState(0, 1)CAS替换尝试获取锁如果成功，替换exclusiveOwnerThread为当前线程
2.如果CAS失败，调用>>acquire(1)>>tryAcquire(1)>>tryAcquire(1)>>
再次尝试获取锁
 如果锁的state为0（锁没有被占用）（与公平锁的区别是这里不用判断当前节点是否有前驱节点），没有则CAS替换state锁状态为1独占,有则获取锁失败(公平锁必须让排队让前驱节点先获取锁).
 如果state不为0，则判断getExclusiveOwnerThread()当前独占线程是否是当前线程，不是则获取锁失败，是当前线程将state加1(获取锁次数加1).
之后的逻辑与公平锁2一致.
```

主要步骤

1.尝试获取锁（如果直接CAS替换state+1，或者独占线程为当前线程则成功），获取失败就创建一个独占节点用CAS替换tail\(放入同步队列尾部\)，

2.如果当前节点的前驱节点是head再次尝试获取锁（跟1.的尝试锁步骤一致），

​               如果成功，将当前节点设为head;

​                如果失败,阻塞当前线程。

可重入

允许中断

AbstractQueueSyncronizer 由两种 等待队列 和条件队列组成

Sync同步器

state 记录上锁次数

exclusiveOwnerThread 独占锁的线程

锁 特性管理

#### AQS内部维护属性

state表示资源的可用状态  获取锁的次数

State三种访问方式

getState\(\)、setState\(\)、compareAndSetState\(\)

#### Node

```
         /** waitStatus值，表示线程已被取消（等待超时或者被中断）*/
         static final int CANCELLED =  1;
         /** waitStatus值，表示后继线程需要被唤醒（unpaking）*/
          static final int SIGNAL    = -1;
          /**waitStatus值，表示结点线程等待在condition上，当被signal后，会从等待队列转移到同步到队列中 */
          /** waitStatus value to indicate thread is waiting on condition */
         static final int CONDITION = -2;
        /** waitStatus值，表示下一次共享式同步状态会被无条件地传播下去
        static final int PROPAGATE = -3;
         /** 等待状态，初始为0 */
         volatile int waitStatus;
         /**当前结点的前驱结点 */
         volatile Node prev;
         /** 当前结点的后继结点 */
         volatile Node next;
        /** 与当前结点关联的排队中的线程 */
        volatile Thread thread;
```

#### 同步等待队列

双向链表来实现

![](/assets/aqs2.png)

结构 head-&gt;Node1&lt;=&gt;Node2&lt;-tail

当线程获取资源失败（比如tryAcquire时试图设置state状态失败），会被构造成一个结点加入CLH队列中，同时当前线程会被阻塞在队列中（通过LockSupport.park实现，其实是等待态）。当持有同步状态的线程释放同步状态时，会唤醒后继结点，然后此结点线程继续加入到对同步状态的争夺中。

阻塞等待队列

AQS当中的同步等待队列也称CLH队列，CLH队列是Craig、Landin、

Hagersten三人发明的一种基于双向链表数据结构的队列，是FIFO先入先出线程等待队列，Java中的CLH队列是原CLH队列的一个变种,线程由原自旋机制改为阻

塞机制。

#### 条件等待队列

单向链表

firstWaiter\(Node\)--&gt;Node1-&gt;Node2-&gt;firstWaiter\(Node\)

nextWaiter获取下一个节点

功能类似Object 监视器方法（wait、notify 和 notifyAll）

```
  await()阻塞当前同步队列中的节点并释放锁
  1.如果当前线程被中断则直接抛出异常
  2.调用addConditionWaiter加入条件队列
  3.释放掉已经获取的独占锁资源fullyRelease（）
  4.如果当前节点不在同步队列阻塞当前线程(isOnSyncQueue返回false就是在)，在就调用acquireQueued方法尝试获取锁
     isOnSyncQueue根据
        node.waitStatus == Node.CONDITION或者当前节点的前驱节点为空（同步队列才有前驱节点），则不在
        当前节点的下一个节点不为空则在同步队列
        从当前节点开始向前轮询同步队列，如果当前节点等于tail节点则在同步队列，如果tail或者当前节点的前驱节点等于空则不在.   
  5.如果获取锁成功并且中断状态不是异常中断（ THROW_IE    = -1），将中断状态改为 interruptMode = REINTERRUPT;（该模式表示在退出等待时重新中断）
  6.如果节点的下一个节点nextWaiter不等于空，轮询队列清除节点状态不为Condition的节点，根据不同中断状态，如果中断状态为THROW_IE抛出异常，如果中断状态为REINTERRUPT中断当前线程。

 signal()将条件队列的节点放入同步队列去竞争锁
 1.判断isHeldExclusively()当前节点没有持有锁就抛出异常。
 2.如果条件队列firstWaiter不为空，执行唤醒firstWaiter。
 3.》》doSignal唤醒
      3.1》》轮询取出条件队列传入transferForSignal (firstWaiter)直到transferForSignal返回true或者条件队列为空
            3.1.1 用CAS替换当前节点waitStatus为0，失败则返回false.
            3.1.2 将当前节点加入同步队列尾部当中，返回前驱节点
            3.1.3 前驱节点的waitStatus>0或者CAS替换前驱节点的waitStatus为SIGNAL失败，则唤醒当前节点，最后返回true
```

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只

需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护

（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器

#### 实现时主要实现以下几种方法：

isHeldExclusively\(\)：该线程是否正在独占资源。只有用到

condition才需要去实现它。

tryAcquire\(int\)：独占方式。尝试获取资源，成功则返回true，失败

则返回false。

tryRelease\(int\)：独占方式。尝试释放资源，成功则返回true，失败

则返回false。

tryAcquireShared\(int\)：共享方式。尝试获取资源。负数表示失败；

0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。

tryReleaseShared\(int\)：共享方式。尝试释放资源，如果释放后允许

唤醒后续等待结点返回true，否则返回false。

##### 可重入

多次获取锁，递归里面调用一个带锁的方法（不可重入会造成死锁）

允许中断

### ReentrantReadWriteLock

读写锁

读写锁对于同步状态的实现是在一个整形变量上通过“按位切割使用”：将变量切割成两部分，高16位表示读，低16位表示写。

1）获取写状态：

​    S&0x0000FFFF:将高16位全部抹去

（2）获取读状态：

​    S&gt;&gt;&gt;16:无符号补0，右移16位

内部维护一个读锁一个写锁

```
/** Inner class providing readlock */
private final ReentrantReadWriteLock.ReadLock readerLock;
/** Inner class providing writelock */
private final ReentrantReadWriteLock.WriteLock writerLock；

读锁共享获取过程
1.子类ReadLock里的>>lock()>>sync.acquireShared(1)>>tryAcquireShared(int unused) 
2.如果获取独占锁的次数不等于0并且独占线程不是当前线程直接获取失败 return -1;
3.判断读锁是否应该阻塞，判断依据
公平锁
FairSync》》readerShouldBlock 有前驱节点应该阻塞返回true
非公平锁
NonfairSync》》readerShouldBlock》》apparentlyFirstQueuedIsExclusive有写请求都返回true
如果不应该阻塞，并且读锁小于读锁最大获取数量，并且CAS替换state读锁数量加1成功。
   如果是第一次加读锁,则firstReader赋值为当前线程，firstReaderHoldCount(第一次获得读锁线程持有的锁的次数)等于1；
   如果firstReader等于当前线程，则firstReaderHoldCount++；
   如果上面的两个条件都不满足，
      则判断如果cachedHoldCounter（每线程读取保持计数的计数器。作为threadlocal维护，缓存）等于null或者线程id不等于当前线程id，readHolds.get()赋值给cachedHoldCounter。
      如果cachedHoldCounter.count(缓存里锁计数器为0)，保存到readHolds；
      cachedHoldCounter.count++；
   return 1；

如果应该阻塞，或者读锁大于或等于读锁最大获取数量，并且CAS替换state读锁数量加1失败。
     执行》》fullTryAcquireShared
      轮询上面的操作直到
      1.第一步return -1;
      2.读锁应该阻塞，cachedHoldCounter.count==0 return -1;
      3.大于读锁最大获取次数抛出异常
      4.return 1;
      这几种情况;


其中exclusiveCount方法表示占有写锁的线程数量，源码如下：
static int exclusiveCount(int c) { return c & EXCLUSIVE_MASK; }
说明：直接将状态state和（2^16 - 1）做与运算，其等效于将state模上2^16。写锁数量由state的低十六位表示。

4.tryAcquireShared(int unused)返回-1 则获取锁失败去排队>>doAcquireShared
  共享的状态加入同步队列中addWaiter(Node.SHARED)
  判断如果前驱节点是head 节点，则再次tryAcquireShared尝试获取锁，如果成功设置node为head节点，设置node.waitStatus->Node.PROPAGATE，然后唤醒node.thread。

读锁释放
ReadLock>>unlock()>>sync.releaseShared(1)>>
tryReleaseShared(arg)
1.如果firstReader等于当前线程
   如果firstReaderHoldCount==1（当前线程获取读锁次数为1），firstReader==null;
   否则firstReaderHoldCount--.
如果firstReader不等于当前线程
   如果缓存计数器cachedHoldCounter==null或者线程id不等于当前线程id,readHolds.get();覆盖掉cachedHoldCounter.
   如果cachedHoldCounter.count缓存数量小于等于1， readHolds.remove();
         如果cachedHoldCounter.count缓存数量小于等于0抛出异常
   --rh.count;
2.轮询直到CAS替换state=state-1成功,如果state==0则return true;
3.如果tryReleaseShared失败 return false;
4.如果tryReleaseShared成功，唤醒后面的节点去竞争锁
      >>doReleaseShared()
      如果head不为null并且head不等于tail
         如果head的waitStatus为SIGNAL,CAS替换head的waitStatus为0失败中断该次循环;
         唤醒head节点（此时head、head.next的线程都唤醒了，head.next会去竞争锁，成功后head会指向获取锁的节点，head会发生变化）
         如果head的waitStatus为0，CAS替换head的waitStatus为共享（PROPAGATE可以传播到后面的共享节点 ），然后跳出此次循环;
      如果以上没有跳出循环，head没有发生变化（表示没有竞争锁了） 跳出循环
```

写锁获取过程

```
WriteLock >>lock()>>sync.acquire(1);>>
1.如果state不等于0（不是初始状态）
      如果写锁获取数量等于0或者当前线程，直接返回 return false;
      如果写锁获取数量大于最大数量（根据）抛出异常
      state加1，return true;
2.writerShouldBlock
  判断如果读锁应该阻塞，判断依据如下，或者CAS替换state加1失败，直接返回false；
     公平锁
     FairSync》》writerShouldBlock 有前驱节点应该阻塞返回true
     非公平锁
     都返回false
  设置setExclusiveOwnerThread(current);独占线程为当前线程，return true;

释放过程
  >>unlock()>> sync.release(1)
  >>tryRelease(arg)
    判断如果当前线程不是独占线程抛出异常，state减1
       如果state减1后写锁获取数量（ exclusiveCount(state减1)）为0，赋值独占线程为null,return true;
    如果tryRelease失败returnfalse
    如果tryRelease成功
     判断如果head不为null并且head的waitStatus不为0，唤醒后继节点,return true;
```

而读写锁有以下三个重要的特性：

（1）公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。

（2）重进入：读锁和写锁都支持线程重进入。

（3）锁降级：遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为读锁。

一个线程要想同时持有写锁和读锁，必须先获取写锁再获取读锁；写锁可以“降级”为读锁；读锁不能“升级”为写锁。如果先获取读锁再获取写锁会造成死锁

### Syncronized JVM内置锁 原理

synchronized是一种独占式的重量级锁，在运行到同步方法或者同步代码块的时候，让程序的运行级别由用户态切换到内核态，把所有的线程挂起，通过操作系统的指令，去调度线程。这样会频繁出现程序运行状态的切换，线程的挂起和唤醒，会消耗系统资源，为了提高效率，JDK1.6开始引入了偏向锁、轻量级锁、尽量让多线程访问公共资源的时候，不进行程序运行状态的切换。

synchronized是在jvm中实现，是基于进入和退出Monitor对象来实现方法和代码块的同步

> 同步代码块：

monitorenter指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor与之相关联，当且一个monitor被持有之后，他将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权，即尝试获取对象的锁；

synchronized内置锁是一种对象锁\(锁的是对象而非引用\)，作用粒度是对象，可以用来实现对临界资源的同步互斥访问，是可重入的。

加锁的方式：

同步实例方法，锁是当前实例对象

同步类方法，锁是当前类对象

同步代码块，锁是括号里面的对象

synchronized是基于JVM内置锁实现，通过内部对象Monitor\(监视器锁\)实现，基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖 底层操作系统的Mutex lock（互斥锁）实现，它是一个重量级锁性能较低（在java1.5及以前）。JVM内置锁在1.5之后版本做了重大的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等 技术来减少锁操作的开销，，内置锁的并发性能已经基本与Lock持平。

synchronized关键字被编译成字节码后会被翻译成monitorenter 和 monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置。

![](/assets/sync1.png)

每个同步对象都有一个自己的Monitor\(监视器锁\)，加锁过程如下图所示：

##### ![](/assets/sync2.png)

锁状态是被记录在每个对象的对象头（Mark Word）

#### 对象的内存布局

HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：

对象头（Header）：比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象）等

实例数据（Instance Data）：即创建对象时，对象中成员变量，方法等

对齐填充（Padding）：对象的大小必须是8字节的整数倍

![](/assets/sync3.png)

对象头

HotSpot虚拟机的对象头包括两部分信息，第一部分是“Mark Word”，用于存储对象自身的运行时数据， 如**哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳**等等，这部分数据的长度在32位和64位的虚拟机（暂 不考虑开启压缩指针的场景）中分别为32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额 外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下。

![](/assets/sync4.png)

但是如果对象是数组类型，则需要三个机器码，因为JVM虚拟机可以通过

Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数

组的大小，所以用一块来记录数组长度。

对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟

机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内

存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，

Mark Word会随着程序的运行发生变化，变化状态如下（32位虚拟机）：

![](/assets/sync5.png)

##### 

**多线程下synchronized的加锁就是对同一个对象的对象头中的MarkWord中的变量进行CAS操作.**

#### MarkWord

Mark Word用于存储对象自身的运行时数据, 如**HashCode, GC分代年龄, 锁状态标志, 线程持有的锁, 偏向线程ID**等.

类型指针

类型指针指向对象的类元数据, 虚拟机通过这个指针确定该对象是哪个类的实例.

#### 锁的膨胀升级过程

锁可以升级, 但不能降级. 即: 无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁是单向的.

下面看一下每个锁状态时, 对象头中的MarkWord这一个字节中的内容是什么. 以32位为例

| bitfields | 标志位\(2bit\) | 状态 | 特征 |
| --- | --- | --- | --- |
| 指向当前锁记录的指针 | 00 | 轻量级锁 | 自旋 |
| hashCode,对象分代年龄,0\(不是偏向\) | 01 | 无锁 |  |
| Thread ID，epoch（偏向时间戳）,对象分代年龄,1\(不是偏向\) | 01 | 偏向锁 | CAS比较ThreadID |
| 指向重量级锁monitor的指针 | 10 | 重量级锁 | 依赖mutex |
|  | 11 | 可GC | 用于标记GC |

Syncronized锁的膨胀 无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁

锁的状态总共有四种，**无锁状态、偏向锁、轻量级锁和重量级锁**。随着锁的 竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级。

#### 无锁

未进入同步块（不通过阻塞的方式来访问并修改资源。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改线程会修改失败，前文提到的CAS就是一个无锁的形式）。

#### 偏向锁

偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁\(会涉及到一些CAS操作,耗时\)的代价而引 入偏向锁。偏向锁的核心思想是，**如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作**，即获取锁的过程，这样就省去了大量有关锁申请的操作，从 而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失效后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。

假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。  
在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行**加锁**或者**解锁**操作，

当线程 1 访问同步块（为无锁状态）时通过CAS成功获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，因为偏向锁不会主动释放锁，因此以后线程 1 再次获取锁的时候，需要比较当前线程的线程 ID 和对象头中的线程 ID 是否一致.

如果一致（还是线程 1 获取锁对象），则无需使用 CAS 来加锁、解锁；

如果不一致（其他线程，如线程 2 要竞争锁对象，而偏向锁不会主动释放因此还是存储的线程 1 的线程 ID），那么需要查看对象头中记录的线程 1 是否存活，如果没有存活，那么锁对象被重置为无锁状态，其它线程（线程 2）可以竞争将其设置为偏向锁；

如果存活，那么立刻查找该线程（线程 1）的栈帧信息，如果还是需要继续持有这个锁对象，那么挂机当前线程 1，撤销偏向锁，升级为轻量级锁，如果线程 1 不再使用该锁对象，那么将锁对象状态设为无锁状态，重新偏向新的线程。

#### 轻量级锁

轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环\(这也是称为自旋的原因\)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。

**锁消除**

消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时\(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编 译\)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种 方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的 append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量， 并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情 景，JVM会自动将其锁消除。

**自旋**

当有个线程A去请求某个锁的时候，这个锁正在被其它线程占用，但是线程A并不会马上进入阻塞状态，而是**循环请求锁\(自旋\)**。这样做的目的是因为很多时候持有锁的线程会很快释放锁的，线程A可以尝试一直请求锁，没必要被挂起放弃CPU时间片，因为线程被挂起然后到唤醒这个过程开销很大,当然如果线程A自旋指定的时间还没有获得锁，仍然会被挂起。

**自适应性自旋**

自适应性自旋是自旋的升级、优化，**自旋的时间不再固定**，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态决定。例如线程如果自旋成功了，那么下次自旋的次数会增多，因为JVM认为既然上次成功了，那么这次自旋也很有可能成功，那么它会允许自旋的次数更多。反之，如果对于某个锁，**自旋很少成功，那么在以后获取这个锁的时候，自旋的次数会变少甚至忽略，避免浪费处理器资源**。有了自适应性自旋，随着程序运行和性能监控信息的不断完善，JVM对程序锁的状况预测就会变得越来越准确，JVM也就变得越来越聪明。

#### 锁细化

在使用锁的时候，需要让同步块的作用范围尽可能小，这样做的目的是**为了使需要同步的操作数量尽可能小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁**。

**逃逸分析**

使用逃逸分析，编译器可以对代码做如下优化：

一、同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可

以不考虑同步。

二、将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远

不会逃逸，对象可能是栈分配的候选，而不是堆分配。

三、分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问

到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。

**自适应性自旋**：自适应性自旋是自旋的升级、优化，自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态决定。例如**线程如果自旋成功了，那么下次自旋的次数会增多**，因为`JVM`认为既然上次成功了，那么这次自旋也很有可能成功，那么它会允许自旋的次数更多。如果**对于某个锁，自旋很少成功**，那么在以后获取这个锁的时候，自旋的次数会变少甚至忽略，避免浪费处理器资源。

#### 偏向锁，轻量级锁，重量级锁对比

| 锁 | 优点 | 缺点 | 适用场景 |
| --- | --- | --- | --- |
| 偏向锁 | 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 | 适用于只有一个线程访问同步块场景（只有一个线程进入临界区） |
| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度 | 如果始终得不到索竞争的线程，使用自旋会消耗CPU | 追求响应速度，同步块执行速度非常快（多个线程交替进入临界区） |
| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU | 线程阻塞，响应时间缓慢 | 追求吞吐量，同步块执行速度较慢（多个线程同时进入临界区） |

**获取锁过程**

1.在线程进入同步方法、同步块的时候，如果同步对象锁状态为无锁状态\(锁标志位为"01"状态，是否为偏向锁为"0"\)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录\(Lock Recored\)的空间，用于储存锁对象目前的Mark Word的拷贝\(官方把这份拷贝加了个Displaced前缀，即Displaced Mark Word\)。

2.将对象头的Mark Word拷贝到线程的锁记录\(Lock Recored\)中。

3.拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新成功了，则执行步骤4，否则执行步骤5。

4.更新成功，这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为"00"，即表示此对象处于轻量级锁的状态。。

5.更新失败，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行，否则说明这个锁对象已经被其其它线程抢占了。进行自旋执行步骤3，如果自旋结束仍然没有获得锁，轻量级锁就需要膨胀为重量级锁，锁标志位状态值变为"10"，Mark Word中储存就是指向monitor对象的指针，当前线程以及后面等待锁的线程也要进入阻塞状态。

无锁-&gt;偏向锁

在线程进入同步方法、同步块的时候 ，此时对象锁标志位01状态（无锁或偏向锁），是否偏向标志为0（未偏向），再用CAS替换MarkWord 中线程ID指向自己修改成功，倒数第三位是否偏向改成1是偏向，偏向锁不会自动释放，没有人竞争会一直偏向拿到它的线程。

偏向锁-&gt;轻量级锁

线程进入同步方法、同步块的时候 ,此时对象锁标志位01状态（无锁或偏向锁），是否偏向标志为1（已偏向）,这时会先判断偏向锁的线程id是不是等于当前线程id，（如果等于直接进去同步块）不等于的话尝试一次CAS替换ThreadID（如果尝试的时候持有偏向锁的线程刚好退出了同步块就会成功这种情况。），如果失败向JVM申请竞争锁，持有偏向锁的线程（**到达安全点暂停线程**）去尝试释放偏向锁（等待竞争出现才会释放偏向锁）检查持有偏向锁的线程状态，如果已退出同步块执行解锁同时将偏向由1改为0，如果未退出则升级锁为轻量级锁，持有偏向锁的线程栈分配一块空间存储锁记录（LockRecord）将MarkWord复制过来，MarkWord存储指向锁记录的指针。

轻量级锁-&gt;重量级锁

线程进入同步方法、同步块的时候 ,此时对象锁标志位00状态（轻量级锁），线程栈分配一块空间存储锁记录（将 MarkWord复制过来\)，CAS操作将对象头的MarkWord中锁记录的指针修改为指向当前线程。如果成功，获取轻量级锁执行同步代码块，执行完轻量级锁解锁（标志位改成01，偏向改成0）。如果失败，锁自旋\(循环请求尝试\)自旋到一点次数CAS操作依然没有成功，当前线程阻塞挂起升级为重量级锁（将标志改为10，指针指向重量级锁的monitor指针），当前线程执行同步块代码，释放锁，唤醒阻塞挂起的锁。

**释放锁的过程**

使用CAS操作将对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来\(依据Mark Word中锁记录指针是否还指向本线程的锁记录\)，如果替换成功，则执行步骤2，否则执行步骤3。  
如果替换成功，整个同步过程就完成了，恢复到无锁的状态\(01\)。

如果替换失败，说明有其他线程尝试获取该锁\(此时锁已膨胀\)，那就要在释放锁的同时，唤醒被挂起的线程。



##### Lock与synchronized有以下区别：

Lock是一个接口，而synchronized是关键字。

synchronized会自动释放锁，而Lock必须手动释放锁。

Lock可以让等待锁的线程响应中断，而synchronized不会，线程会一直等待下去。

通过Lock可以知道线程有没有拿到锁，而synchronized不能。

Lock能提高多个线程读操作的效率。

synchronized能锁住类、方法和代码块，而Lock是块范围内的



